---
title: "annotations_final_project"
author: "Carolina Downie"
date: "12/4/2017"
output: html_document
---

#Motivation and Questions 

When our group was brainstorming what our final Data Science project would be, we started by looking for large public health-related datasets that were available on the web. We quickly found data about hospital rankings and comparisons from [Medicare](https://data.medicare.gov/data/hospital-compare), and decided it would be interesting to analyze the hospital rankings based on factors like geography, type of hospital ownership, and some of the criteria used to create the rankings. 
Upon doing some further reading, we learned that the roll-out of these Medicare Hospital Compare rankings in July 2016 was [controversial](https://www.usnews.com/news/articles/2016-07-27/medicare-releases-controversial-hospital-star-ratings). Many hospitals criticized the rankings, claiming that these scores were not accurate. Furthermore, there were complaints that major hospitals that consistently score highly in US News and World Reports rankings and other commercial rankings did not score highly on the [Medicare rankings](https://www.npr.org/sections/health-shots/2016/07/27/487633215/many-well-known-hospitals-fail-to-score-high-in-medicare-rankings), and instead relatively obscure hospitals received the highest rating (a rating of 5 stars). 
Given this information, we decided to analyze the Medicare data assess these claims. 
Questions that drove our analysis were:

* What was the geographic distribution of ratings? Did areas of the country that are known for having well-known hospital systems (eg NYC, Boston) have high Medicare scores? In what areas of the country were there hospitals with the lowest scores? 

* How did the distribution of ratings vary by hospital ownership type? 

* Were there important differences in the Top 20 Hospitals in 2016-2017 as ranked by [US News and World Reports](https://web.archive.org/web/20160816171510/http://health.usnews.com/health-care/best-hospitals/articles/best-hospitals-honor-roll-and-overview) and the corresponding 2016 Medicare scores for these hospitals (i.e. were the complaints of these hospitals justified)? 

* Can we make a logistic model for patient satisfaction score based on other known hospital ranking criteria? 

#Data

**Medicare Hospital Data**

*About the dataset*

The main dataset that we chose to analyze was the [Hospital General Information](https://data.medicare.gov/Hospital-Compare/Hospital-General-Information/xubh-q36u/data) dataset, which is published by the Centers for Medicare & Medicaid Services and contains information about all hospitals in the United States (and U.S. Territories) that have been registered with Medicare. According to the Medicare [website](https://data.medicare.gov/Hospital-Compare/Hospital-General-Information/xubh-q36u/about), this dataset was created in May 2014 and was last updated in October 2017. We downloaded the datset as a csv file from [Data.Medicare.gov](https://data.medicare.gov/Hospital-Compare/Hospital-General-Information/xubh-q36u/data) by clicking on the "Export" tab and selecting the CSV option from the Download section, which allowed us to download a copy of the dataset in a static format. 

The [Hospital Compare](https://www.cms.gov/medicare/quality-initiatives-patient-assessment-instruments/hospitalqualityinits/hospitalcompare.html) is a program that was created in 2002 which provides "information on how well hospitals provide recommended care to their patients," based on a variety of measures including patient experiences, readmissions & death rates, payment & value of care. In 2016, "Overall Hospital Quality Star Rating" was added to the Hospital Compare metrics. More information about hospital ratings methodology can be found [here](https://www.qualitynet.org/dcs/ContentServer?c=Page&pagename=QnetPublic%2FPage%2FQnetTier3&cid=1228775957165) and [here](http://www.hcahpsonline.org/Files/October_2017_Star%20Ratings_Tech%20Notes.pdf). 


*Data cleaning*

In order to make a plot of the geographic distribution of hospital rankings, we needed to have the latitude and longitude of the hospitals; this information was provided in the "Location" variable, but as a coordinate pair, and with the accompanying address. To address this, we applied the `separate` function twice, first to separate `coordinates` and `address`, and then to separate `coordinates` into `latitude` and `longitude`. 

However, when we looked through the resulting dataset, we noticed that there were quite a few hospitals that didn't have latitude and longitude coordinates, which would prohibit us from being able to plot them on a map. To address this, we applied the `geocode` function from the `ggmap` package to the dataset, which takes an input address and provides the corresponding 
latitude and longitude. 

We first applied `ggmap::geocode` using the `address` variable to look up coordinates; however after running this, we still had several hospitals for which it wasn't able to find coordinates. So we then did the same thing, but using `hospital_name` as the input address information to try to find the coordinates for the hospitals that we had missed using `address`. After applying this process, there were only 4 hospitals for which we could not find corresponding geographical coordinates; since none of these were major, well-known hospitals, we removed them from the dataset. We then joined this dataset to our initial hospital dataset to replace the missing latitude and longitude values. We saved this updated dataset, which contained geographic coordinates for all of the hospitals as a csv file called `hospital_data_2` and used this dataset for all of our analyses.  



**US News and World Reports Dataset**

*About the dataset*

Every year, US News & World Reports ranks US hospitals across 16 different medical specialities based on a variety of measures, including survival, patient safety, and care-related indicators. The Best Hospitals Honor Roll is a list of the top 20 hospitals that had the highest ratings across all 16 Best Hospital specialties, nine procedures, and condition ratings. Total points for hospitals on the Best Hospital Honor Roll list are out of a maximum of **448**. More information about the US News & World Reports methodology for the 2016-2017 rankings can be found [here](http://web.archive.org/web/20160910084826/http://static.usnews.com:80/documents/health/best-hospitals/BH_Methodology_2016-17.pdf).   

*Data scraping and cleaning*

In order to be able to make comparisons to the US News and World Reports hospital rankings, we needed to scrape this data from the webpage where this information is listed. Because we wanted the rankings plus information about the US News and World Reports points/scoring criteria, we had to do a bit of searching to get the right data for the 2016-2017 ranking cycle. After first looking [here](https://www.usnews.com/info/blogs/press-room/articles/2016-08-02/us-news-announces-the-201617-best-hospitals) (which had rankings, but no points), and [here](https://health.usnews.com/health-care/best-hospitals/articles/best-hospitals-honor-roll-and-overview) (which had rankings and points, but was for 2017-2018), we realized we could use [web.archive.org](web.archive.org) to find the archived 2016-2017 rankings page with points, which we found [here](https://web.archive.org/web/20160816171510/http://health.usnews.com/health-care/best-hospitals/articles/best-hospitals-honor-roll-and-overview). 
Because we considered comparing the Medicare rankings to both the 2016-2017 and 2017-2018 rankings (and the webpages for these were in the same format), we wrote a function to scrape the US News & World Reports data. We converted the `points` variable from a factor to a numeric value. 

***EXPLANATION OF score normalization and comparison. 


#Exploratory analysis:

We started our exploratory analysis by visualizing relationships of interest. This included hospital rating based on ownership (boxplot), hospital rating based on hospital type (boxplot), hospital rating distribution (barplot), and hospital rating vs. Patient Experience Level (Scatter plot). After this preliminary analysis, we recognized that these graphs were not particularly useful in visualizations for describing our data, however the preliminary analysis emphasized our interest to further explore patient experience through basic logistic regression. 

Additionally, after reading some articles about controversial Medicare rankings we decided to compare US Scores and rankings to the Medicare rankings to see if there are any major discrepancies in scores. We were also interested in looking how the score of a hospital changed by region and ownership (Houston and UCLA showed major discrepancies between the two rating mechanisms). Our final logistic regression model looked at patient experience as the outcome and ownership (5 categories with government as the reference category), type (binary - critical care access available or not) and overall score (continous: scale from 1-5) as predictors.

 Our final logistic regression model looked at patient experience as the outcome and ownership, type, and overall rating as predictors. We were interested to see how these factors influenced patient experience. Predictors which signficianyly affected patient experience were ownershhip, overall rating, and ... We initiially used all categories of all variable in our model but with the low overall count found in the government-state, government-local, government-Hospital District or Authority, and government-federal; decided to collapse into one governmental dummy variable. 


#Discussion:
NEED MORE INFO HERE

